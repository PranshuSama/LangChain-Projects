{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbe4b658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_huggingface\n",
      "  Obtaining dependency information for langchain_huggingface from https://files.pythonhosted.org/packages/81/ce/502157ef7390a31cc67e5873ad66e737a25d1d33fcf6936e5c9a0a451409/langchain_huggingface-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.33.4 (from langchain_huggingface)\n",
      "  Obtaining dependency information for huggingface-hub<1.0.0,>=0.33.4 from https://files.pythonhosted.org/packages/a8/af/48ac8483240de756d2438c380746e7130d1c6f75802ef22f3c6d49982787/huggingface_hub-0.36.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from langchain_huggingface) (1.2.7)\n",
      "Collecting tokenizers<1.0.0,>=0.19.1 (from langchain_huggingface)\n",
      "  Obtaining dependency information for tokenizers<1.0.0,>=0.19.1 from https://files.pythonhosted.org/packages/2e/47/174dca0502ef88b28f1c9e06b73ce33500eedfac7a7692108aec220464e7/tokenizers-0.22.2-cp39-abi3-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/b5/36/7fb70f04bf00bc646cd5bb45aa9eddb15e19437a28b8fb2b4a5249fac770/filelock-3.20.3-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/e6/ab/fb21f4c939bb440104cc2b396d3be1d9b7a9fd3c6c2a53d98c45b3d7c954/fsspec-2026.2.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2026.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface)\n",
      "  Obtaining dependency information for hf-xet<2.0.0,>=1.1.3 from https://files.pythonhosted.org/packages/7f/8c/c5becfa53234299bc2210ba314eaaae36c2875e0045809b82e40a9544f0c/hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/7f/8c/c5becfa53234299bc2210ba314eaaae36c2875e0045809b82e40a9544f0c/hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/7f/8c/c5becfa53234299bc2210ba314eaaae36c2875e0045809b82e40a9544f0c/hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (6.0.3)\n",
      "Requirement already satisfied: requests in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.67.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.15.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.6.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2.12.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.11.6)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.0.0)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2026.1.4)\n",
      "Requirement already satisfied: anyio in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (4.12.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/pranshu/Documents/LangChain/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.16.0)\n",
      "Downloading langchain_huggingface-1.2.0-py3-none-any.whl (30 kB)\n",
      "Downloading huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m77.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.2-cp39-abi3-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m227.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2026.2.0-py3-none-any.whl (202 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.5/202.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m187.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: hf-xet, fsspec, filelock, huggingface-hub, tokenizers, langchain_huggingface\n",
      "Successfully installed filelock-3.20.3 fsspec-2026.2.0 hf-xet-1.2.0 huggingface-hub-0.36.2 langchain_huggingface-1.2.0 tokenizers-0.22.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a4ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_classic.prompts import PromptTemplate\n",
    "from langchain_classic.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43844152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 18.2 (Windows)', 'creationdate': '2023-09-09T07:52:17-04:00', 'author': 'U.S. Census Bureau', 'keywords': 'acsbr-015', 'moddate': '2023-09-12T14:44:47+01:00', 'title': 'Health Insurance Coverage Status and Type by Geography: 2021 and 2022', 'trapped': '/false', 'source': 'us_census/acsbr-015.pdf', 'total_pages': 18, 'page': 0, 'page_label': '1'}, page_content='Health Insurance Coverage Status and Type \\nby Geography: 2021 and 2022\\nAmerican Community Survey Briefs\\nACSBR-015\\nIssued September 2023\\nDouglas Conway and Breauna Branch\\nINTRODUCTION\\nDemographic shifts as well as economic and govern-\\nment policy changes can affect people’s access to \\nhealth coverage. For example, between 2021 and 2022, \\nthe labor market continued to improve, which may \\nhave affected private coverage in the United States \\nduring that time.\\n1 Public policy changes included \\nthe renewal of the Public Health Emergency, which \\nallowed Medicaid enrollees to remain covered under \\nthe Continuous Enrollment Provision.\\n2 The American \\nRescue Plan (ARP) enhanced Marketplace premium \\nsubsidies for those with incomes above 400 percent \\nof the poverty level as well as for unemployed people.\\n3\\nIn addition to national policies, individual states and \\nthe District of Columbia can affect health insurance \\ncoverage by making Marketplace or Medicaid more')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read pdf from us_census\n",
    "loader = PyPDFDirectoryLoader(\"./us_census\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000,chunk_overlap = 200)\n",
    "\n",
    "final_document = text_splitter.split_documents(documents=documents)\n",
    "final_document[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd9fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hugging face embeddings\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name = \"BAAI/bge-small-en-v1.5\",\n",
    "    model_kwargs = {'device' : 'cpu'},\n",
    "    encode_kwargs = {'normalize_embeddings' : True}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de4ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.30602124e-02, -1.45066725e-02, -2.10276563e-02,  2.72682551e-02,\n",
       "        4.53646928e-02,  5.28341383e-02, -2.53758840e-02,  3.61304283e-02,\n",
       "       -9.08312276e-02, -2.77017690e-02,  7.97398165e-02,  6.42475337e-02,\n",
       "       -3.54004763e-02, -4.04245183e-02, -1.13771278e-02,  4.45296392e-02,\n",
       "       -3.88545846e-03, -3.79056227e-03, -4.54509966e-02,  2.67047361e-02,\n",
       "       -2.05682125e-02,  2.87432224e-02, -2.41201594e-02, -3.69411856e-02,\n",
       "        1.92781016e-02,  1.06194885e-02,  3.21827410e-03,  2.33256840e-03,\n",
       "       -4.29321788e-02, -1.64999247e-01,  2.77008000e-03,  2.68277284e-02,\n",
       "       -4.12894562e-02, -1.88446753e-02,  1.58918798e-02,  9.22327489e-03,\n",
       "       -2.00688243e-02,  8.16561580e-02,  3.89413126e-02,  5.52223064e-02,\n",
       "       -3.69984396e-02,  1.75319500e-02, -1.28966980e-02,  2.80628010e-04,\n",
       "       -2.51580775e-02,  4.59334999e-03, -2.39578318e-02, -5.76557498e-03,\n",
       "        6.02946477e-03, -3.61178443e-02,  3.84415947e-02, -1.75463501e-03,\n",
       "        5.05655929e-02,  6.02408759e-02,  4.52067107e-02, -4.91434857e-02,\n",
       "        1.82054304e-02, -1.46668097e-02, -2.53130384e-02,  3.18243802e-02,\n",
       "        5.15598319e-02, -9.32343490e-03, -2.61889279e-01,  1.00012645e-01,\n",
       "        1.34968832e-02,  4.36564311e-02, -6.08387263e-03, -4.54133144e-03,\n",
       "       -3.26450095e-02, -4.28530909e-02, -5.28034344e-02,  4.51760478e-02,\n",
       "       -4.90110144e-02,  1.14362491e-02,  3.36463340e-02,  2.09724065e-02,\n",
       "        1.38647901e-02,  5.93815790e-03,  1.49723189e-02, -8.11344851e-03,\n",
       "        1.01394793e-02,  2.79459711e-02, -6.45076763e-03, -4.83987518e-02,\n",
       "        4.86142151e-02, -8.64626020e-02,  5.24354167e-02, -3.35654505e-02,\n",
       "        3.21201123e-02, -3.52678150e-02, -3.55471447e-02,  1.33937029e-02,\n",
       "       -2.35927268e-03,  3.77090052e-02,  6.75871037e-03,  3.44192199e-02,\n",
       "       -5.24623739e-03, -8.69446807e-03, -1.43432170e-02,  3.42605859e-01,\n",
       "       -2.61228904e-02,  9.80757177e-03, -2.25788653e-02,  8.17080121e-03,\n",
       "       -9.10547096e-03, -6.63615912e-02, -3.31288041e-03,  3.76485963e-03,\n",
       "        1.78495776e-02,  1.94205884e-02,  1.89167671e-02, -2.34020147e-02,\n",
       "        1.70286223e-02,  3.59937102e-02, -5.00385799e-02, -2.86068283e-02,\n",
       "        3.76006551e-02,  1.95080023e-02,  9.70121846e-02, -2.35506650e-02,\n",
       "       -5.60349366e-03,  4.08104211e-02, -1.22215683e-02, -4.84442413e-02,\n",
       "        1.59177687e-02,  7.82314688e-02,  5.22117540e-02,  1.41182423e-01,\n",
       "        3.60795557e-02, -3.56155336e-02,  1.04116239e-01, -4.85004298e-02,\n",
       "       -9.04245209e-03, -3.47386609e-04, -3.86379776e-03,  1.05186552e-02,\n",
       "       -1.18664121e-02,  4.76750657e-02, -1.44308330e-02,  4.32955995e-02,\n",
       "        1.39372293e-02, -9.43202060e-03, -3.39478906e-03, -1.30119145e-01,\n",
       "       -2.24879086e-02,  1.85143068e-01, -3.77383232e-02,  4.94089648e-02,\n",
       "        1.73503980e-02, -2.00506058e-02, -4.56999540e-02,  6.15431145e-02,\n",
       "       -3.38922217e-02,  3.41245346e-02, -3.52289490e-02,  2.25264300e-02,\n",
       "       -3.88042326e-03,  2.96608582e-02, -3.23118046e-02, -5.61317131e-02,\n",
       "        5.52870817e-02, -3.27033997e-02, -4.70694266e-02,  1.33565413e-02,\n",
       "        4.41281199e-02, -2.02731378e-02, -1.62062738e-02, -5.46822958e-02,\n",
       "        2.79455408e-02,  9.90033709e-03,  1.44526800e-02,  5.46371415e-02,\n",
       "        2.29170639e-02, -2.23384127e-02,  9.18254927e-02,  2.43631788e-02,\n",
       "       -3.52479592e-02, -8.27394985e-03, -5.45696355e-03, -5.42017147e-02,\n",
       "       -5.69419097e-03, -2.11966261e-02, -5.15157208e-02, -4.83904853e-02,\n",
       "       -1.58691201e-02, -3.49855796e-02, -6.40029162e-02,  4.69647609e-02,\n",
       "        5.08957282e-02, -1.47770904e-02, -2.62474036e-03,  9.61359590e-03,\n",
       "       -5.30826747e-02,  3.27618606e-02, -1.20410901e-02,  1.89264014e-03,\n",
       "       -6.53932616e-02, -2.97078080e-02,  4.61532064e-02, -3.11540533e-02,\n",
       "       -3.44942659e-02,  2.73555648e-02,  1.33985765e-02, -1.12299491e-02,\n",
       "       -5.48388017e-03,  1.20182103e-02,  3.20996530e-02, -7.33810291e-02,\n",
       "        4.33215313e-02, -1.46467239e-02, -6.26267912e-03,  4.07445692e-02,\n",
       "        2.55041663e-02,  1.34797324e-03,  3.32123227e-02,  2.35809591e-02,\n",
       "        1.29890395e-02, -2.96592377e-02,  9.96720511e-04,  3.23757939e-02,\n",
       "        3.47309485e-02,  7.43661150e-02,  8.83725807e-02, -2.74852753e-01,\n",
       "       -5.02364198e-03,  6.73112832e-03,  5.10843983e-03, -7.25276619e-02,\n",
       "       -5.16856164e-02, -3.50604393e-02,  2.54639070e-02,  5.96719189e-03,\n",
       "        9.32260230e-02,  6.52372241e-02, -1.24274576e-02, -2.26454232e-02,\n",
       "        1.03852808e-01,  2.69624200e-02, -5.88308200e-02,  3.26073505e-02,\n",
       "       -2.70967633e-02, -1.62646379e-02,  3.82239721e-03,  1.43361883e-03,\n",
       "       -1.74208335e-03, -5.87847009e-02, -2.54904967e-06,  8.17155465e-02,\n",
       "       -8.29951430e-04,  6.18573353e-02, -5.67797497e-02, -7.95385912e-02,\n",
       "        8.72034114e-03, -5.23827970e-02,  4.91904020e-02, -1.34030227e-02,\n",
       "       -1.09614693e-01,  6.37905970e-02,  1.59761384e-02, -8.35732445e-02,\n",
       "       -1.80335063e-02, -5.23566753e-02, -2.67081000e-02, -2.57245600e-02,\n",
       "        5.58587089e-02, -6.18519150e-02,  1.82368867e-02, -1.30652068e-02,\n",
       "       -5.21241128e-02,  4.50306907e-02,  6.84902072e-02, -7.28626400e-02,\n",
       "        4.47438890e-03,  8.44440144e-03, -2.58527584e-02, -2.72553954e-02,\n",
       "       -8.25330243e-03,  2.65438426e-02, -6.06658831e-02, -3.46958786e-02,\n",
       "        2.65969150e-02, -1.06718987e-02, -6.09569810e-03,  2.14285124e-02,\n",
       "        4.35659662e-03,  3.98480482e-02, -7.30905076e-03,  7.62288168e-04,\n",
       "       -4.81284931e-02,  9.06979665e-03, -2.74650902e-02, -6.46280125e-02,\n",
       "        7.81238638e-03,  6.36901415e-04,  3.72855663e-02, -2.43166555e-02,\n",
       "       -2.94920541e-02,  2.59610321e-02, -2.04743538e-02,  2.99484767e-02,\n",
       "       -3.93523136e-03, -7.24741397e-03, -4.70116436e-02,  4.60673012e-02,\n",
       "       -6.55132160e-02,  1.94678567e-02,  4.70717922e-02, -4.82359109e-03,\n",
       "        1.85412895e-02,  1.27155641e-02,  9.35989060e-03, -1.63067821e-02,\n",
       "        1.78641099e-02, -1.42972302e-02, -1.85641032e-02, -1.11413095e-02,\n",
       "       -2.76977941e-02, -1.63668266e-03,  1.32832313e-02, -2.23142415e-01,\n",
       "        5.02430685e-02,  3.20568159e-02, -2.58731898e-02,  7.37161143e-03,\n",
       "       -1.69073008e-02, -1.84587371e-02,  1.52461184e-02, -1.25951357e-02,\n",
       "       -1.74231529e-02,  4.49848361e-02,  8.47080871e-02,  1.25501961e-01,\n",
       "       -1.12586664e-02, -9.03834030e-03, -4.29149112e-03,  7.40758330e-02,\n",
       "       -5.70523087e-03,  2.40515154e-02, -4.09415141e-02,  5.69055490e-02,\n",
       "       -6.37594461e-02,  1.52565405e-01, -1.74385980e-02,  1.57482829e-02,\n",
       "       -7.21550509e-02, -2.26559732e-02,  3.81210595e-02, -4.17390652e-02,\n",
       "        1.38447033e-02,  1.97878424e-02,  1.08574210e-02,  1.14634046e-02,\n",
       "       -1.90664995e-02,  6.13893867e-02,  4.67908336e-03,  1.12024071e-02,\n",
       "        4.75127585e-02,  4.35520243e-03,  3.34495641e-02, -5.18546626e-02,\n",
       "       -1.82738360e-02,  9.24018957e-03,  2.57450039e-03,  6.83403537e-02,\n",
       "       -3.80241051e-02, -5.42042814e-02, -7.67753497e-02, -8.67898669e-03,\n",
       "        6.64248317e-02,  9.31190327e-03, -3.73430178e-02, -2.34105671e-03,\n",
       "       -5.78064891e-03, -5.70392273e-02, -6.05429756e-03, -5.90126030e-02,\n",
       "        3.92624326e-02, -8.48791283e-03, -1.47276344e-02,  2.09183544e-02,\n",
       "        5.32475822e-02, -7.08249062e-02,  1.93986278e-02,  6.82188570e-02])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "array = np.array(huggingface_embeddings.embed_query(final_document[0].page_content))\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae49a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "print(array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12931f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x131116990>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = FAISS.from_documents(final_document[:120],huggingface_embeddings)\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3298a098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 U.S. Census Bureau\n",
      "WHAT IS HEALTH INSURANCE COVERAGE?\n",
      "This brief presents state-level estimates of health insurance coverage \n",
      "using data from the American Community Survey (ACS). The  \n",
      "U.S. Census Bureau conducts the ACS throughout the year; the \n",
      "survey asks respondents to report their coverage at the time of \n",
      "interview. The resulting measure of health insurance coverage, \n",
      "therefore, reflects an annual average of current comprehensive \n",
      "health insurance coverage status.* This uninsured rate measures a \n",
      "different concept than the measure based on the Current Population \n",
      "Survey Annual Social and Economic Supplement (CPS ASEC). \n",
      "For reporting purposes, the ACS broadly classifies health insurance \n",
      "coverage as private insurance or public insurance. The ACS defines \n",
      "private health insurance as a plan provided through an employer \n",
      "or a union, coverage purchased directly by an individual from an \n",
      "insurance company or through an exchange (such as healthcare.\n"
     ]
    }
   ],
   "source": [
    "## query search\n",
    "query = \"What is health insurance coverage?\"\n",
    "relevant_documents = vectorstore.similarity_search(query=query)\n",
    "print(relevant_documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1020b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['FAISS', 'HuggingFaceEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x131116990> search_kwargs={'k': 3}\n"
     ]
    }
   ],
   "source": [
    "## retriever\n",
    "retriever = vectorstore.as_retriever(search_type = \"similarity\",search_kwargs = {\"k\":3})\n",
    "print(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48cb772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "hf_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "if not hf_api_key:\n",
    "    raise RuntimeError(\"HUGGINGFACE_API_KEY is not set. Add it to .env or export it in your shell.\")\n",
    "os.environ[\"HUGGINGFACE_API_KEY\"] = hf_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fab801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health insurance coverage refers to the financial protection provided to an individual or their family in the event of medical expenses or healthcare services. It is a type of insurance that helps pay for or reimburse medical costs incurred by the policyholder, either themselves or their dependents.\n",
      "\n",
      "Health insurance coverage typically includes a range of benefits, such as:\n",
      "\n",
      "1. **Medical expenses**: Coverage for doctor visits, hospital stays, surgeries, and other medical procedures.\n",
      "2. **Preventive care**: Coverage for routine health screenings, vaccinations, and check-ups.\n",
      "3. **Prescription medications**: Coverage for prescription medications, including brand-name and generic options.\n",
      "4. **Emergency services**: Coverage for emergency room visits, ambulance services, and other urgent care services.\n",
      "5. **Chronic condition management**: Coverage for ongoing treatment and management of chronic conditions, such as diabetes or asthma.\n",
      "6. **Mental health services**: Coverage for mental health services, including therapy, counseling, and hospitalization.\n",
      "7. **Hospital stays**: Coverage for hospital stays, including room and board, meals, and medical services.\n",
      "\n",
      "Health insurance coverage can be obtained through various sources, including:\n",
      "\n",
      "1. **Employer-sponsored plans**: Many employers offer health insurance coverage as a benefit to their employees.\n",
      "2. **Individual plans**: Individuals can purchase health insurance coverage directly from an insurance company or through a health insurance marketplace.\n",
      "3. **Medicare**: A government-run health insurance program for individuals aged 65 and older, as well as certain younger individuals with disabilities.\n",
      "4. **Medicaid**: A government-run health insurance program for low-income individuals and families.\n",
      "5. **Private insurance companies**: Individuals can purchase health insurance coverage from private insurance companies.\n",
      "\n",
      "The types of health insurance coverage available vary widely, and the specific benefits and features of a plan can depend on the insurance company, the policy type, and the level of coverage chosen.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Use Llama 3.1 - It is a primary production model for 2026\n",
    "hf = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    huggingfacehub_api_token=hf_api_key,\n",
    "    max_new_tokens=500,\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=hf)\n",
    "\n",
    "query = \"What is health insurance coverage?\"\n",
    "messages = [HumanMessage(content=query)]\n",
    "\n",
    "# This should avoid the 410 error\n",
    "response = chat_model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71934e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Hugging Face models can be run locally through the HuggingFacePipeline class.\n",
    "# from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "# hf = HuggingFacePipeline.from_model_id(\n",
    "#     model_id=\"mistralai/Mistral-7B-v0.1\",\n",
    "#     task=\"text-generation\",\n",
    "#     pipeline_kwargs={\"temperature\": 0, \"max_new_tokens\": 300}\n",
    "# )\n",
    "\n",
    "# llm = hf \n",
    "# llm.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c39b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following piece of context to answer the question asked.\n",
    "Please try to provide the answer only based on the context\n",
    "\n",
    "{context}\n",
    "Question:{question}\n",
    "\n",
    "Helpful Answers:\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d8426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=prompt_template,input_variables=[\"context\",\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5bb64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "    llm = hf,\n",
    "    chain_type = 'stuff',\n",
    "    retriever = retriever,\n",
    "    return_source_documents = True,\n",
    "    chain_type_kwargs = {\"prompt\" : prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efb57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"DIFFERENCES IN THE\n",
    "UNINSURED RATE BY STATE\n",
    "IN 2022\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81077c15",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model Qwen/Qwen2.5-7B is not supported for task text-generation and provider featherless-ai. Supported task: conversational.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# call the QA\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ans = \u001b[43mretrievalQA\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(ans[\u001b[33m'\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_classic/chains/base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    166\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    169\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    170\u001b[39m     )\n\u001b[32m    172\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    173\u001b[39m         inputs,\n\u001b[32m    174\u001b[39m         outputs,\n\u001b[32m    175\u001b[39m         return_only_outputs,\n\u001b[32m    176\u001b[39m     )\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_classic/chains/retrieval_qa/base.py:154\u001b[39m, in \u001b[36mBaseRetrievalQA._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    153\u001b[39m     docs = \u001b[38;5;28mself\u001b[39m._get_docs(question)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcombine_documents_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_documents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_run_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_source_documents:\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mself\u001b[39m.output_key: answer, \u001b[33m\"\u001b[39m\u001b[33msource_documents\u001b[39m\u001b[33m\"\u001b[39m: docs}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:205\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    204\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_classic/chains/base.py:637\u001b[39m, in \u001b[36mChain.run\u001b[39m\u001b[34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[39m\n\u001b[32m    632\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[32m0\u001b[39m], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[32m    633\u001b[39m         _output_key\n\u001b[32m    634\u001b[39m     ]\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[32m    638\u001b[39m         _output_key\n\u001b[32m    639\u001b[39m     ]\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    642\u001b[39m     msg = (\n\u001b[32m    643\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    644\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m but none were provided.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    645\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:205\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    204\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_classic/chains/base.py:413\u001b[39m, in \u001b[36mChain.__call__\u001b[39m\u001b[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[32m    381\u001b[39m \n\u001b[32m    382\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    404\u001b[39m \u001b[33;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[32m    405\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    406\u001b[39m config = {\n\u001b[32m    407\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks,\n\u001b[32m    408\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: tags,\n\u001b[32m    409\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    410\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m: run_name,\n\u001b[32m    411\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRunnableConfig\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_classic/chains/base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    166\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    169\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    170\u001b[39m     )\n\u001b[32m    172\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    173\u001b[39m         inputs,\n\u001b[32m    174\u001b[39m         outputs,\n\u001b[32m    175\u001b[39m         return_only_outputs,\n\u001b[32m    176\u001b[39m     )\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_classic/chains/combine_documents/base.py:141\u001b[39m, in \u001b[36mBaseCombineDocumentsChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[32m    140\u001b[39m other_keys = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs.items() \u001b[38;5;28;01mif\u001b[39;00m k != \u001b[38;5;28mself\u001b[39m.input_key}\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m output, extra_return_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_run_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mother_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m extra_return_dict[\u001b[38;5;28mself\u001b[39m.output_key] = output\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_classic/chains/combine_documents/stuff.py:266\u001b[39m, in \u001b[36mStuffDocumentsChain.combine_docs\u001b[39m\u001b[34m(self, docs, callbacks, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m inputs = \u001b[38;5;28mself\u001b[39m._get_inputs(docs, **kwargs)\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m, {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_classic/chains/llm.py:315\u001b[39m, in \u001b[36mLLMChain.predict\u001b[39m\u001b[34m(self, callbacks, **kwargs)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs: Any) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    301\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[32m    302\u001b[39m \n\u001b[32m    303\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    313\u001b[39m \u001b[33;03m        ```\u001b[39;00m\n\u001b[32m    314\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m.output_key]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:205\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    204\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_classic/chains/base.py:413\u001b[39m, in \u001b[36mChain.__call__\u001b[39m\u001b[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[32m    381\u001b[39m \n\u001b[32m    382\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    404\u001b[39m \u001b[33;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[32m    405\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    406\u001b[39m config = {\n\u001b[32m    407\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks,\n\u001b[32m    408\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: tags,\n\u001b[32m    409\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    410\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m: run_name,\n\u001b[32m    411\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRunnableConfig\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_classic/chains/base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    165\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    166\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    169\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    170\u001b[39m     )\n\u001b[32m    172\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    173\u001b[39m         inputs,\n\u001b[32m    174\u001b[39m         outputs,\n\u001b[32m    175\u001b[39m         return_only_outputs,\n\u001b[32m    176\u001b[39m     )\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_classic/chains/llm.py:117\u001b[39m, in \u001b[36mLLMChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    114\u001b[39m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m    115\u001b[39m     run_manager: CallbackManagerForChainRun | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    116\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.create_outputs(response)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_classic/chains/llm.py:129\u001b[39m, in \u001b[36mLLMChain.generate\u001b[39m\u001b[34m(self, input_list, run_manager)\u001b[39m\n\u001b[32m    127\u001b[39m callbacks = run_manager.get_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm, BaseLanguageModel):\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m results = \u001b[38;5;28mself\u001b[39m.llm.bind(stop=stop, **\u001b[38;5;28mself\u001b[39m.llm_kwargs).batch(\n\u001b[32m    136\u001b[39m     cast(\u001b[33m\"\u001b[39m\u001b[33mlist\u001b[39m\u001b[33m\"\u001b[39m, prompts),\n\u001b[32m    137\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks},\n\u001b[32m    138\u001b[39m )\n\u001b[32m    139\u001b[39m generations: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Generation]] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_core/language_models/llms.py:789\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    780\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    782\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     **kwargs: Any,\n\u001b[32m    787\u001b[39m ) -> LLMResult:\n\u001b[32m    788\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_core/language_models/llms.py:1011\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    992\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    993\u001b[39m     run_managers = [\n\u001b[32m    994\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    995\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1009\u001b[39m         )\n\u001b[32m   1010\u001b[39m     ]\n\u001b[32m-> \u001b[39m\u001b[32m1011\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n\u001b[32m   1019\u001b[39m     run_managers = [\n\u001b[32m   1020\u001b[39m         callback_managers[idx].on_llm_start(\n\u001b[32m   1021\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1028\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[32m   1029\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_core/language_models/llms.py:815\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    805\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    806\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    811\u001b[39m     **kwargs: Any,\n\u001b[32m    812\u001b[39m ) -> LLMResult:\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    814\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    816\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    819\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    822\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    823\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    824\u001b[39m         )\n\u001b[32m    825\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    826\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_core/language_models/llms.py:1505\u001b[39m, in \u001b[36mLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1502\u001b[39m new_arg_supported = inspect.signature(\u001b[38;5;28mself\u001b[39m._call).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1503\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m   1504\u001b[39m     text = (\n\u001b[32m-> \u001b[39m\u001b[32m1505\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m   1507\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(prompt, stop=stop, **kwargs)\n\u001b[32m   1508\u001b[39m     )\n\u001b[32m   1509\u001b[39m     generations.append([Generation(text=text)])\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/langchain_huggingface/llms/huggingface_endpoint.py:341\u001b[39m, in \u001b[36mHuggingFaceEndpoint._call\u001b[39m\u001b[34m(self, prompt, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    338\u001b[39m         completion += chunk.text\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m completion\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m response_text = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minvocation_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;66;03m# Maybe the generation has stopped at one of the stop sequences:\u001b[39;00m\n\u001b[32m    348\u001b[39m \u001b[38;5;66;03m# then we remove this stop sequence from the end of the generated text\u001b[39;00m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m stop_seq \u001b[38;5;129;01min\u001b[39;00m invocation_params[\u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/huggingface_hub/inference/_client.py:2357\u001b[39m, in \u001b[36mInferenceClient.text_generation\u001b[39m\u001b[34m(self, prompt, details, stream, model, adapter_id, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[39m\n\u001b[32m   2355\u001b[39m model_id = model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model\n\u001b[32m   2356\u001b[39m provider_helper = get_provider_helper(\u001b[38;5;28mself\u001b[39m.provider, task=\u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m, model=model_id)\n\u001b[32m-> \u001b[39m\u001b[32m2357\u001b[39m request_parameters = \u001b[43mprovider_helper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2362\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2364\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2366\u001b[39m \u001b[38;5;66;03m# Handle errors separately for more precise error messages\u001b[39;00m\n\u001b[32m   2367\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/huggingface_hub/inference/_providers/_common.py:93\u001b[39m, in \u001b[36mTaskProviderHelper.prepare_request\u001b[39m\u001b[34m(self, inputs, parameters, headers, model, api_key, extra_payload)\u001b[39m\n\u001b[32m     90\u001b[39m api_key = \u001b[38;5;28mself\u001b[39m._prepare_api_key(api_key)\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# mapped model from HF model ID\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m provider_mapping_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_mapping_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# default HF headers + user headers (to customize in subclasses)\u001b[39;00m\n\u001b[32m     96\u001b[39m headers = \u001b[38;5;28mself\u001b[39m._prepare_headers(headers, api_key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/.venv/lib/python3.11/site-packages/huggingface_hub/inference/_providers/_common.py:171\u001b[39m, in \u001b[36mTaskProviderHelper._prepare_mapping_info\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not supported by provider \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m provider_mapping.task != \u001b[38;5;28mself\u001b[39m.task:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    172\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not supported for task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.task\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and provider \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    173\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSupported task: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprovider_mapping.task\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m provider_mapping.status == \u001b[33m\"\u001b[39m\u001b[33mstaging\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    177\u001b[39m     logger.warning(\n\u001b[32m    178\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is in staging mode for provider \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Meant for test purposes only.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    179\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Model Qwen/Qwen2.5-7B is not supported for task text-generation and provider featherless-ai. Supported task: conversational."
     ]
    }
   ],
   "source": [
    "# call the QA\n",
    "ans = retrievalQA.invoke({\"query\" : query})\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4509d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Hmm, the user is asking about differences in the uninsured rate by state in 2022 based on the context provided. Let me go through the information carefully. \n",
      "\n",
      "The key points I can extract about state-level differences in 2022 are: Massachusetts had the lowest uninsured rate while Texas had the highest. This is explicitly stated in the context. \n",
      "\n",
      "The document also indicates that Medicaid expansion status correlated with coverage patterns. Expansion states had higher private and public coverage rates than nonexpansion states in both 2021 and 2022. Specifically, Medicaid coverage was 22.7% in expansion states versus 18.0% in nonexpansion states. \n",
      "\n",
      "Regarding geographic trends, Utah had the highest private coverage rate (tied with North Dakota) and lowest public coverage, while New Mexico showed the opposite pattern with highest public coverage and lowest private coverage. \n",
      "\n",
      "For year-over-year changes, only Maine saw an increase in uninsured rates (from 5.7% to 6.6%), while 27 states saw decreases - particularly Medicaid expansion states. The national comparison shows expansion states started with better coverage in both categories. \n",
      "\n",
      "I should present these findings clearly: the extremes (MA/Texas), the Medicaid expansion effect, and the unique state profiles like Utah and New Mexico. Since the user specifically asked about 2022 differences, I'll focus on that year's data while mentioning relevant context from 2021 where it helps explain trends. The Medicaid coverage comparison seems particularly important as it explains part of the interstate variation.\n",
      "</think>\n",
      "Based on the provided context, here are the key differences in uninsured rates by state for 2022:\n",
      "\n",
      "1.  **Extremes in Uninsured Rates:?**\n",
      "    *   **Lowest:** Massachusetts had the lowest uninsured rate.\n",
      "    *   **Highest:** Texas had the highest uninsured rate.\n",
      "\n",
      "2.  **Medicaid Expansion Status Impact:**\n",
      "    *   States that expanded Medicaid eligibility generally had lower uninsured rates.\n",
      "    *   These expansion states also had higher rates of **both** private and public coverage compared to non-expansion states in both 2021 and 2022.\n",
      "    *   Medicaid coverage specifically was significantly higher in expansion states (22.7%) compared to non-expansion states (18.0%).\n",
      "\n",
      "3.  **Key Coverage Patterns:?**\n",
      "    *   **Highest Private Coverage:** Utah had the highest rate of private health insurance coverage in 2022 (tied with North Dakota, where the rates were not\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "# 1. Use DeepSeek-R1 - It is the most active serverless model in 2026\n",
    "# We force 'together' as the provider because it is the most stable for this ID\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"deepseek-ai/DeepSeek-R1\",\n",
    "    huggingfacehub_api_token=hf_api_key,\n",
    "    provider=\"together\",  # This is the 'secret sauce' to avoid the 404/410\n",
    "    max_new_tokens=512,\n",
    ")\n",
    "\n",
    "# 2. You MUST wrap it in ChatHuggingFace for RetrievalQA to work in 2026\n",
    "chat_model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "# 3. Use the chat_model in your QA chain\n",
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    ")\n",
    "\n",
    "# 4. Invoke\n",
    "query = \"DIFFERENCES IN THE UNINSURED RATE BY STATE IN 2022\"\n",
    "ans = retrievalQA.invoke({\"query\": query})\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2d37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Hmm, the user is asking about differences in the uninsured rate by state in 2022 based on the provided context. The context includes information about Medicaid expansion states versus non-expansion states, changes in uninsured rates from 2021 to 2022, and specific state examples.\n",
      "\n",
      "Looking at the context, it mentions that Massachusetts had the lowest uninsured rate while Texas had the highest in 2022. The Medicaid expansion status appears to be a key factor - expansion states had higher coverage rates (both private and public) than non-expansion states. The context also notes that uninsured rates decreased in 27 states (mainly Medicaid expansion states) and only Maine had an increase.\n",
      "\n",
      "For public versus private coverage patterns, Utah had the highest private coverage and lowest public coverage, while New Mexico showed the opposite pattern with highest public coverage and lowest private coverage. The document also references the District of Columbia but doesn't provide its specific uninsured rate in the included text.\n",
      "\n",
      "The key differences mentioned in the context are primarily between expansion and non-expansion states, with specific examples of high and low extremes for uninsured rates and coverage types.\n",
      "</think>\n",
      "Based solely on the context:\n",
      "\n",
      "1.  **Massachusetts had the lowest uninsured rate in 2022.**\n",
      "2.  **Texas had the highest uninsured rate in 2022.**\n",
      "3.  **Medicaid expansion status was a key differentiator:** States that expanded Medicaid eligibility had higher private coverage rates and higher public coverage rates in both 2021 and 2022 compared to states that did not expand Medicaid.\n",
      "4.  **Coverage type extremes:**\n",
      "    *   **Utah** had the highest private coverage rate and the lowest public coverage rate in 2022.\n",
      "    *   **New Mexico** had the highest public coverage rate and the lowest private coverage rate in 2022.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "# 1. Take your exact prompt and put it in a HumanMessage\n",
    "# We use HumanMessage because it's the most reliable way to send custom formatting to Instruct models\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Use the following piece of context to answer the question asked.\n",
    "Please try to provide the answer only based on the context\n",
    "\n",
    "{context}\n",
    "\n",
    "Question:{question}\n",
    "\n",
    "Helpful Answers: \"\"\")\n",
    "\n",
    "# 2. Re-initialize the RetrievalQA with this prompt\n",
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model, # Your working DeepSeek/Llama chat model\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt} # This injects your template\n",
    ")\n",
    "\n",
    "# 3. Call the QA\n",
    "query = \"DIFFERENCES IN THE UNINSURED RATE BY STATE IN 2022\"\n",
    "ans = retrievalQA.invoke({\"query\": query})\n",
    "print(ans['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c5d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfeb89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35824907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
